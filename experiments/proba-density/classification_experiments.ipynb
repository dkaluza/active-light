{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from al.sampling.uncert import off_centered_entropy, entropy_info\n",
    "from al.sampling.uncert.classification.prior import ClassWeightedEntropy\n",
    "from al.sampling.baseline import random\n",
    "from al.sampling.combination import InfoEnsemble, ProductAggregation, SumAggregation\n",
    "from al.sampling.repr.pr_density import PrDensity\n",
    "from al.sampling.repr.knn import k_nearest_neighbor_repr\n",
    "from al.sampling.kernels import UniformKernel, GaussianKernel, ConstantBandwidth, SilvermanTactic, ScottTactic\n",
    "from al.sampling.qbc import BootstrapJS\n",
    "import torch\n",
    "from al.distances import L2Distance, JensenShannonDistance\n",
    "from al.plot.results import plot_metric\n",
    "\n",
    "from al.loops.base import ALDataset, LoopConfig, LoopMetric\n",
    "from al.loops.experiments import ExperimentResults, NClassesGuaranteeWrapper, XGBWrapper, create_AL_dataset_from_openml, run_experiment\n",
    "from al.loops.perfect_oracle import active_learning_loop\n",
    "import xgboost\n",
    "from al.kde import NaiveKDE, ClusteringKDE\n",
    "from torch.utils.data import TensorDataset\n",
    "import pandas as pd\n",
    "from al.base import ImbalancedModelPriorPredictTactic\n",
    "\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2437f969250>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_device('cuda')\n",
    "\n",
    "torch.manual_seed(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_firefighters():\n",
    "    path_prefix = '../../datasets/firefighters/'\n",
    "    data_files = ['train.csv', 'test.csv']\n",
    "    X = pd.concat([pd.read_csv(path_prefix + path, header=0) for path in data_files], axis=0)\n",
    "    y = X[\"labelPose\"].astype('category')\n",
    "    X = X.drop(columns=[\"labelPose\", \"labelAction\"])\n",
    "    X = torch.tensor(X.to_numpy())\n",
    "    y = torch.tensor(y.cat.codes.to_numpy(), dtype=torch.int64)\n",
    "    return ALDataset(TensorDataset(X, y.squeeze()))\n",
    "\n",
    "def load_sod():\n",
    "    path_prefix = '../../datasets/sod/'\n",
    "    x_files = ['x_loop.csv', 'x_experts_kb.csv', 'x_test.csv']\n",
    "    y_files = ['y_loop.csv', 'y_experts_kb.csv', 'y_test.csv']\n",
    "    X = pd.concat([pd.read_csv(path_prefix + path, header=None) for path in x_files], axis=0)\n",
    "    y = pd.concat([pd.read_csv(path_prefix + path, header=None) for path in y_files], axis=0)\n",
    "\n",
    "    X = torch.tensor(X.to_numpy())\n",
    "    y = torch.tensor(y.to_numpy())\n",
    "    return ALDataset(TensorDataset(X, y.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Inf\\active-light\\.conda\\Lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# To run experiment with appropriate dataset uncomment the selected line and comment out others.\n",
    "\n",
    "# To obtain firefighters or sod dataset please contact knowledgepit.ml platform administrators,\n",
    "# data from those datasets should be placed in datasets folder in the main repo as indicated\n",
    "# by functions defined in the previous cell.\n",
    "\n",
    "# datasets with experiments with NaiveKDE\n",
    "\n",
    "# dataset, save_path = ALDataset(create_AL_dataset_from_openml(554).dataset), './mnist_final.bin'\n",
    "# dataset, save_path = load_firefighters(), './firefighters_final.bin'\n",
    "\n",
    "# datasets with experiments with ClusterringKDE\n",
    "\n",
    "dataset, save_path = ALDataset(create_AL_dataset_from_openml(1596).dataset), './covertype_final.bin'\n",
    "# dataset, save_path = ALDataset(create_AL_dataset_from_openml(182).dataset), './satimage_final.bin'\n",
    "# dataset, save_path = ALDataset(create_AL_dataset_from_openml(6).dataset), './letter_final.bin'\n",
    "\n",
    "# datasets with custom hyperparams \n",
    "# dataset, save_path = load_sod(), './sod_final.bin'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'36% 49% 6% 0% 2% 3% 4%'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priors = torch.bincount(dataset.targets) / torch.bincount(dataset.targets).sum()\n",
    "priors = [prior.item() for prior in priors]\n",
    "priors_formated = \" \".join([f\"{prior:.0%}\" for prior in priors])\n",
    "priors_formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290306 & 290506 & 98 & 7 & 36% 49% 6% 0% 2% 3% 4%\n"
     ]
    }
   ],
   "source": [
    "dataset_desc = f\"{len(dataset) *0.5 -200 :.0f} & {len(dataset)* 0.5 :.0f} & {dataset.features.shape[1]} & {len(priors)} & \" + priors_formated\n",
    "print(dataset_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gausian_kernel = GaussianKernel()\n",
    "uniform_kernel = UniformKernel()\n",
    "l2_distance = L2Distance()\n",
    "\n",
    "\n",
    "kde_estimator =   functools.partial(ClusteringKDE, index_device=torch.device(\"cpu\")) \n",
    "\n",
    "# Uncomment for naive KDE implementation\n",
    "# kde_estimator = NaiveKDE\n",
    "\n",
    "knn_entropy = InfoEnsemble([entropy_info, k_nearest_neighbor_repr], aggregation_tactic=ProductAggregation())\n",
    "\n",
    "# FALC methods\n",
    "proba_density_silverman = PrDensity(kernel=uniform_kernel, distance=l2_distance, kde_class=kde_estimator,\n",
    "                                      bandwidth_tactic=SilvermanTactic())\n",
    "proba_density_scott = PrDensity(kernel=uniform_kernel, distance=l2_distance, kde_class=kde_estimator,\n",
    "                                      bandwidth_tactic=ScottTactic())\n",
    "proba_density_silverman_gauss = PrDensity(kernel=gausian_kernel, distance=l2_distance, kde_class=kde_estimator,\n",
    "                                      bandwidth_tactic=SilvermanTactic())\n",
    "proba_density_scott_gauss = PrDensity(kernel=gausian_kernel, distance=l2_distance, kde_class=kde_estimator,\n",
    "                                      bandwidth_tactic=ScottTactic())\n",
    "\n",
    "pr_density_aggregation = ProductAggregation()\n",
    "class_weighted_entropy = ClassWeightedEntropy() # TODO rename to also include proba?\n",
    "proba_density_entropy_silverman = InfoEnsemble([class_weighted_entropy, proba_density_silverman], aggregation_tactic=pr_density_aggregation)\n",
    "proba_density_entropy_scott = InfoEnsemble([class_weighted_entropy, proba_density_scott], aggregation_tactic=pr_density_aggregation)\n",
    "proba_density_entropy_silverman_gauss = InfoEnsemble([class_weighted_entropy, proba_density_silverman_gauss], aggregation_tactic=pr_density_aggregation)\n",
    "proba_density_entropy_scott_gauss = InfoEnsemble([class_weighted_entropy, proba_density_scott_gauss], aggregation_tactic=pr_density_aggregation)\n",
    "\n",
    "\n",
    "qbc = BootstrapJS(n_models=5)\n",
    "\n",
    "\n",
    "uncerts = [proba_density_entropy_scott, proba_density_entropy_silverman, proba_density_entropy_silverman_gauss, proba_density_entropy_scott_gauss,\n",
    "            knn_entropy, qbc, random, entropy_info, off_centered_entropy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnsembleClassWeightedEntropy1.0_ProbaDensityUniformKernelL2DistanceScottTactic1.0\n",
      "EnsembleClassWeightedEntropy1.0_ProbaDensityUniformKernelL2DistanceSilvermanTactic1.0\n",
      "EnsembleClassWeightedEntropy1.0_ProbaDensityGaussianKernelL2DistanceSilvermanTactic1.0\n",
      "EnsembleClassWeightedEntropy1.0_ProbaDensityGaussianKernelL2DistanceScottTactic1.0\n",
      "EnsembleEntropy1.0_KNearestNeighborRepr1.0\n",
      "BootstrapJS\n",
      "Random\n",
      "Entropy\n",
      "OffCenteredEntropy\n"
     ]
    }
   ],
   "source": [
    "for uncert in uncerts:\n",
    "    print(uncert.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoopConfig(metrics=[LoopMetric.BAC, LoopMetric.BAC_from_predict])\n",
    "if save_path.startswith(\"./sod\"):\n",
    "    print(\"using redefined params\")\n",
    "    xgbmodel =  xgboost.XGBClassifier(random_state=42, tree_method='hist', objective='binary:logistic', n_jobs=16, device='cpu',\n",
    "                                       eta=0.1, base_score=0.06) # positive samples are ~6% of data, this comes from domain knowledge\n",
    "else:\n",
    "    xgbmodel =  xgboost.XGBClassifier(random_state=42, tree_method='hist', objective='multi:softprob', n_jobs=16, device='cpu', eta=0.1)\n",
    "model = NClassesGuaranteeWrapper(\n",
    "    XGBWrapper(xgbmodel,\n",
    "        predict_tactic=ImbalancedModelPriorPredictTactic()\n",
    "        ), \n",
    "    n_classes=dataset.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_results = run_experiment(active_learning_loop, data=dataset, infos=uncerts, config=config, model=model, init_frac=200, save_path=save_path, budget=50, n_repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "cProfile.run('run_experiment(active_learning_loop, data=dataset, infos=uncerts, config=config, model=model, init_frac=100, save_path=\"perftest.bin\", budget=30, n_repeats=1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names_mapping = {proba_density_entropy_scott.name: '$FALC_u^{sc}$',\n",
    " proba_density_entropy_silverman.name: '$FALC_u^{si}$',\n",
    " proba_density_entropy_silverman_gauss.name: '$FALC_g^{si}$',\n",
    " proba_density_entropy_scott_gauss.name: '$FALC_g^{sc}$',\n",
    " knn_entropy.name: 'KNN-Entropy',\n",
    " qbc.name: 'BootstrapJS',\n",
    " random.name: 'Random',\n",
    " entropy_info.name: 'Entropy',\n",
    " off_centered_entropy.name: 'Off-Centered Entropy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_paths = ['./mnist_final.bin', './firefighters_final.bin', \n",
    "                  './covertype_final.bin', './satimage_final.bin', \n",
    "                  './letter_final.bin', './sod_final.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for save_path in all_results_paths:\n",
    "    config_results = ExperimentResults.load(save_path)\n",
    "    for metric in (LoopMetric.BAC_from_predict.name, LoopMetric.BAC.name):\n",
    "        plot_metric(config_results, metric, add_mean_to_legened=True, names_mapping=names_mapping)\n",
    "        plt.legend(bbox_to_anchor=(1.02, 1.0), loc='upper left', borderaxespad=0)\n",
    "        plt.xlabel(\"Iteration number\")\n",
    "        if metric == LoopMetric.BAC_from_predict.name:\n",
    "            plt.ylabel(\"$BAC^{mp}$\")\n",
    "        else:\n",
    "            plt.ylabel(\"$BAC$\")\n",
    "        save_path_stripped = save_path.removesuffix('.bin').removeprefix(\"./\")\n",
    "        plt.savefig(f\"images/{metric}_{save_path_stripped}.png\", bbox_inches=\"tight\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_device('cpu')\n",
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uniform_kernel = UniformKernel()\n",
    "l2_distance = L2Distance()\n",
    "\n",
    "clustering_kde_estimator =   functools.partial(ClusteringKDE, index_device=torch.device(\"cpu\")) # NaiveKDE\n",
    "\n",
    "# current implemenmtation of names do not include kde_estimators therefore we have to\n",
    "# patch them to make them distinguishible \n",
    "\n",
    "# FALC methods\n",
    "proba_density_clustering = PrDensity(kernel=uniform_kernel, distance=l2_distance, kde_class=clustering_kde_estimator,\n",
    "                                      bandwidth_tactic=SilvermanTactic())\n",
    "pr_density_aggregation = ProductAggregation()\n",
    "class_weighted_entropy = ClassWeightedEntropy() # TODO rename to also include proba?\n",
    "falc_clussteing_kde =  InfoEnsemble([class_weighted_entropy, proba_density_clustering], aggregation_tactic=pr_density_aggregation)\n",
    "\n",
    "proba_density_naive = PrDensity(kernel=uniform_kernel, distance=l2_distance, kde_class=NaiveKDE,\n",
    "                                      bandwidth_tactic=SilvermanTactic())\n",
    "\n",
    "falc_naive_kde = InfoEnsemble([class_weighted_entropy, proba_density_naive], aggregation_tactic=pr_density_aggregation)\n",
    "\n",
    "from unittest.mock import patch, PropertyMock\n",
    "\n",
    "InfoEnsemble.name = PropertyMock()\n",
    "InfoEnsemble.name = property(lambda self: \"NaiveKDE\" if self is falc_naive_kde else \"ClusteringKDE\")\n",
    "\n",
    "\n",
    "uncerts = [falc_naive_kde, falc_clussteing_kde, entropy_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveKDE\n",
      "ClusteringKDE\n",
      "Entropy\n"
     ]
    }
   ],
   "source": [
    "for uncert in uncerts:\n",
    "    print(uncert.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = None # \"./performance_times_covertype.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoopConfig(return_info_times = True)\n",
    "\n",
    "config_results = run_experiment(active_learning_loop, data=dataset, infos=uncerts, config=config, model=model, init_frac=200, test_frac=0.5, save_path=save_path, budget=1, n_repeats=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from al.plot.results import plot_info_times\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "config_results = ExperimentResults.load(save_path)\n",
    "\n",
    "plot_info_times(config_results)\n",
    "plt.savefig(f\"images/performance_comparison.png\", bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveKDE\n",
      "tensor(2.9858, device='cuda:0')\n",
      "tensor(0.1027, device='cuda:0')\n",
      "ClusteringKDE\n",
      "tensor(3.6132, device='cuda:0')\n",
      "tensor(0.8075, device='cuda:0')\n",
      "Entropy\n",
      "tensor(0.1657, device='cuda:0')\n",
      "tensor(0.0164, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for result, val in config_results.res.items():\n",
    "    print(result)\n",
    "    print(val.info_times.mean())\n",
    "    print(val.info_times.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bac_pred_over_bac(results_paths):\n",
    "    bac_residuals = []\n",
    "    bac_pred_better = []\n",
    "\n",
    "    for save_path in results_paths:\n",
    "        results = ExperimentResults.load(save_path)\n",
    "        for config_name, config_res in results.res.items():\n",
    "            bac_pred = config_res.metrics[LoopMetric.BAC_from_predict.name]\n",
    "            bac_original = config_res.metrics[LoopMetric.BAC.name]\n",
    "            residual = bac_pred - bac_original\n",
    "            bac_residuals.append(residual)\n",
    "            bac_pred_better.append((residual > 0).float())\n",
    "\n",
    "    bac_residuals = torch.stack(bac_residuals)\n",
    "    bac_pred_better = torch.stack(bac_pred_better)\n",
    "    print(bac_residuals.max())\n",
    "    print(bac_residuals.min())\n",
    "    print(bac_pred_better.mean(), bac_residuals.mean(), bac_residuals.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1944)\n",
      "tensor(-0.0044)\n",
      "tensor(0.9800) tensor(0.0264) tensor(0.0414)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "compute_bac_pred_over_bac(all_results_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_results_paths = [ './firefighters_final.bin',  './covertype_final.bin', './sod_final.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1944)\n",
      "tensor(0.0013)\n",
      "tensor(1.) tensor(0.0501) tensor(0.0480)\n"
     ]
    }
   ],
   "source": [
    "compute_bac_pred_over_bac(imbalanced_results_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0195)\n",
      "tensor(-0.0044)\n",
      "tensor(0.9600) tensor(0.0026) tensor(0.0021)\n"
     ]
    }
   ],
   "source": [
    "compute_bac_pred_over_bac(set(all_results_paths) - set(imbalanced_results_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6437276147240704e-21"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from al.loops.stats import friedman_difference_test, pairwise_wilcoxon_test, get_ranks_for_experiment\n",
    "all_results = [ExperimentResults.load(path) for path in all_results_paths]\n",
    "friedman_difference_test(all_results, LoopMetric.BAC_from_predict.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_to_test = [\n",
    "    proba_density_entropy_scott.name, proba_density_entropy_silverman.name, \n",
    "    proba_density_entropy_silverman_gauss.name, proba_density_entropy_scott_gauss.name\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- & - & - & - & \\textbf{***} & \\textbf{***} & \\textbf{***} & * & \\textbf{***} \\\\ \n",
      "- & - & - & - & \\textbf{***} & \\textbf{***} & \\textbf{***} & \\textbf{***} & \\textbf{***} \\\\ \n",
      "- & - & - & - & \\textbf{***} & \\textbf{***} & \\textbf{***} &   & \\textbf{***} \\\\ \n",
      "- & - & - & - & \\textbf{***} & \\textbf{***} & \\textbf{***} & * & \\textbf{***} \\\\ \n"
     ]
    }
   ],
   "source": [
    "pairwise_test_results = pairwise_wilcoxon_test(all_results, LoopMetric.BAC_from_predict.name, pvalue_adjustment_method='by', alternative='greater', configs_to_test=configs_to_test,\n",
    "                                               include_self_comparison=False)\n",
    "pairwise_p_values = pairwise_test_results.pvalues\n",
    "pairwise_configs_names = pairwise_test_results.config_names\n",
    "\n",
    "def bold(str_val):\n",
    "    return r\"\\textbf{\" + str_val + \"}\"\n",
    "\n",
    "def latex_tab_print(val):\n",
    "    # check if this is nan\n",
    "    if val != val:\n",
    "        return \"-\"\n",
    "    \n",
    "    res = f\"{val : 0.3f}\"\n",
    "    \n",
    "    if val > 0.05:\n",
    "        return res\n",
    "    \n",
    "    return bold(res)\n",
    "\n",
    "def latex_significance_tab_print(val):\n",
    "    # check if this is nan\n",
    "    if val != val:\n",
    "        return \"-\"\n",
    "\n",
    "    if val > 0.1:\n",
    "        return \" \"\n",
    "    \n",
    "    if val > 0.05:\n",
    "        return \"*\"\n",
    "    \n",
    "    if val > 0.01:\n",
    "        return \"**\"\n",
    "    \n",
    "    if val < 0.01:\n",
    "        return bold(\"***\")\n",
    "\n",
    "for line in pairwise_p_values[:4]:\n",
    "    print(*[latex_significance_tab_print(val) for val in line.tolist()], sep=\" & \", end=\" \\\\\\\\ \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EnsembleClassWeightedEntropy1.0_ProbaDensityUniformKernelL2DistanceScottTactic1.0',\n",
       " 'EnsembleClassWeightedEntropy1.0_ProbaDensityUniformKernelL2DistanceSilvermanTactic1.0',\n",
       " 'EnsembleClassWeightedEntropy1.0_ProbaDensityGaussianKernelL2DistanceSilvermanTactic1.0',\n",
       " 'EnsembleClassWeightedEntropy1.0_ProbaDensityGaussianKernelL2DistanceScottTactic1.0',\n",
       " 'EnsembleEntropy1.0_KNearestNeighborRepr1.0',\n",
       " 'BootstrapJS',\n",
       " 'Random',\n",
       " 'Entropy',\n",
       " 'OffCenteredEntropy']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_configs_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[       nan,        nan,        nan,        nan, 1.8863e-05, 1.4200e-06,\n",
       "         4.3902e-07, 8.1358e-02, 7.5151e-04],\n",
       "        [       nan,        nan,        nan,        nan, 1.0290e-05, 4.3902e-07,\n",
       "         4.3902e-07, 2.9882e-03, 2.6179e-05],\n",
       "        [       nan,        nan,        nan,        nan, 4.5893e-05, 1.6234e-05,\n",
       "         2.2700e-06, 2.6075e-01, 4.1061e-03],\n",
       "        [       nan,        nan,        nan,        nan, 1.1773e-05, 8.4918e-07,\n",
       "         9.0139e-07, 9.1848e-02, 2.0473e-03],\n",
       "        [       nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan],\n",
       "        [       nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EnsembleClassWeightedEntropy1.0_ProbaDensityUniformKernelL2DistanceScottTactic1.0',\n",
       " 'EnsembleClassWeightedEntropy1.0_ProbaDensityUniformKernelL2DistanceSilvermanTactic1.0',\n",
       " 'EnsembleClassWeightedEntropy1.0_ProbaDensityGaussianKernelL2DistanceSilvermanTactic1.0',\n",
       " 'EnsembleClassWeightedEntropy1.0_ProbaDensityGaussianKernelL2DistanceScottTactic1.0',\n",
       " 'EnsembleEntropy1.0_KNearestNeighborRepr1.0',\n",
       " 'BootstrapJS',\n",
       " 'Random',\n",
       " 'Entropy',\n",
       " 'OffCenteredEntropy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_configs_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./mnist_final.bin\n",
      "3 & 1 & 4 & 2 & 9 & 7 & 8 & 5 & 6 \\\\ \n",
      "./firefighters_final.bin\n",
      "1 & 2 & 3 & 4 & 8 & 6 & 9 & 5 & 7 \\\\ \n",
      "./covertype_final.bin\n",
      "3 & 1 & 2 & 5 & 9 & 8 & 7 & 4 & 6 \\\\ \n",
      "./satimage_final.bin\n",
      "2 & 3 & 4 & 1 & 8 & 6 & 9 & 5 & 7 \\\\ \n",
      "./letter_final.bin\n",
      "3 & 6 & 4 & 5 & 1 & 9 & 8 & 2 & 7 \\\\ \n",
      "./sod_final.bin\n",
      "4 & 2 & 9 & 1 & 7 & 3 & 6 & 8 & 5 \\\\ \n",
      "2.6666666666666665 & 2.5 & 4.333333333333333 & 3.0 & 7.0 & 6.5 & 7.833333333333333 & 4.833333333333333 & 6.333333333333333 \\\\ \n"
     ]
    }
   ],
   "source": [
    "all_rankings = []\n",
    "for result, dataset_name in zip(all_results, all_results_paths):\n",
    "    ranking = get_ranks_for_experiment(result, LoopMetric.BAC_from_predict.name)\n",
    "    print(dataset_name)\n",
    "    ranking = [int(rank) for rank in ranking]\n",
    "    print(*ranking, sep=\" & \", end=\" \\\\\\\\ \\n\")\n",
    "    all_rankings.append(ranking)\n",
    "\n",
    "all_rankings = torch.tensor(all_rankings, dtype=float).mean(axis=0).tolist()\n",
    "print(*all_rankings, sep=\" & \", end=\" \\\\\\\\ \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
